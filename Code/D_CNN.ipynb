{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "# from utils import load_data\n",
    "\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import Sequential \n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "# import torchmetrics accuracy\n",
    "import torchmetrics\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN_IMG = '../CW_Dataset/train/'\n",
    "PATH_TEST_IMG = '../CW_Dataset/test/'\n",
    "PATH_TRAIN_LABEL = '../CW_Dataset/labels/list_label_train.txt'\n",
    "PATH_TEST_LABEL = '../CW_Dataset/labels/list_label_test.txt'\n",
    "\n",
    "# load data\n",
    "X_train_list, y_train_list = load_data(PATH_TRAIN_IMG, PATH_TRAIN_LABEL, gray=True)\n",
    "X_test_list, y_test_list = load_data(PATH_TEST_IMG, PATH_TEST_LABEL, gray=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensors\n",
    "X_train = T.tensor(np.array(X_train_list), dtype=T.float)  # image should be float\n",
    "y_train = T.tensor(np.array(y_train_list), dtype=T.long) - 1  # target should be long | -1 to make 0-6 range\n",
    "X_test = T.tensor(np.array(X_test_list), dtype=T.float)\n",
    "y_test = T.tensor(np.array(y_test_list), dtype=T.long) - 1\n",
    "\n",
    "# Add channel dimension | image size: (channel, height, width)\n",
    "X_train = X_train.unsqueeze(1)\n",
    "X_test = X_test.unsqueeze(1)\n",
    "\n",
    "# convert to tensor dataset (train, val, test)\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_split = int(0.25 * len(train_dataset))\n",
    "train_dataset, val_dataset = random_split(train_dataset, [len(train_dataset) - val_split, val_split])\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# create data loaders (train, val, test) | image size: (batch, channel, height, width)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train obs: {} - Val obs: {} - Test obs: {}'.format(len(train_dataset), len(val_dataset), len(test_dataset)))\n",
    "print('\\nLabel:', train_dataset[0][1])\n",
    "\n",
    "print('\\nImage shape:', train_dataset[0][0].shape)  # dimensions first dataset item\n",
    "\n",
    "batch_x, batch_y = next(iter(train_loader))  # dimensions first data loader batch\n",
    "print('\\nBatch shape:', batch_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitCNN(LightningModule):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.accuracy = torchmetrics.Accuracy()\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        # CNN block - image size 100*100\n",
    "        self.CNN_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        # FC block - image batch size: torch.Size([32, 128, 12, 12])\n",
    "        self.FC_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=128 * 12 * 12, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.CNN_layers(x)\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = self.FC_layers(x)  # no activation and no softmax at the end\n",
    "        return x  \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = T.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=True)\n",
    "        self.log('train_acc', self.accuracy(y_hat, y), prog_bar=True, on_step=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "\n",
    "        self.log('val_loss', loss, prog_bar=True, on_step=True)\n",
    "        self.log('val_acc', self.accuracy(y_hat, y), prog_bar=True, on_step=True)\n",
    "        return loss\n",
    "\n",
    "    # def validation_epoch_end(self, outputs):\n",
    "    #     avg_loss = T.stack([x['val_loss'] for x in outputs]).mean()\n",
    "    #     tensorboard_logs = {'val_loss': avg_loss}\n",
    "    #     return {'val_loss': avg_loss, 'log': tensorboard_logs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = LitCNN(input_size=100*100, num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "logger = TensorBoardLogger('../tensorboard_logs', 'my_model')\n",
    "trainer = pl.Trainer(logger=logger, max_epochs=2, fast_dev_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ../tensorboard_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "y_hat = model(X_test)\n",
    "y_hat = y_hat.argmax(dim=1)\n",
    "y_hat = y_hat.detach().numpy()\n",
    "y_test = y_test.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "print(classification_report(y_test, y_hat))\n",
    "sns.heatmap(confusion_matrix(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('fer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f77961612acb5d081fd2373e515848ecc70065f5f997e07d4c2817dc8deb7852"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
