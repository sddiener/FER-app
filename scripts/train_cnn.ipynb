{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load the images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn import svm, metrics\n",
    "import pickle as pkl\n",
    "\n",
    "from src.utils import load_data, display_n_images, create_SIFT_features, cluster_descriptors, convert_des_to_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\fer\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "# from utils import load_data\n",
    "\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import Sequential \n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "# import torchmetrics accuracy\n",
    "import torchmetrics\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN_IMG = '../CW_Dataset/train/'\n",
    "PATH_TEST_IMG = '../CW_Dataset/test/'\n",
    "PATH_TRAIN_LABEL = '../CW_Dataset/labels/list_label_train.txt'\n",
    "PATH_TEST_LABEL = '../CW_Dataset/labels/list_label_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list, y_train_list = load_data(PATH_TRAIN_IMG, PATH_TRAIN_LABEL, gray=True)\n",
    "X_test_list, y_test_list = load_data(PATH_TEST_IMG, PATH_TEST_LABEL, gray=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample for testing\n",
    "X_train_list = X_train_list[:1000]\n",
    "y_train_list = y_train_list[:1000]\n",
    "X_test_list = X_test_list[:1000]\n",
    "y_test_list = y_test_list[:1000]\n",
    "PRINT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5: 217, 4: 513, 1: 144, 6: 87, 2: 3, 3: 36})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train_list)\n",
    "#display_n_images(X_train_list, y_train_list, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensors\n",
    "X_train = T.tensor(np.array(X_train_list), dtype=T.float)  # image should be float\n",
    "y_train = T.tensor(np.array(y_train_list), dtype=T.long) - 1  # target should be long | -1 to make 0-6 range\n",
    "X_test = T.tensor(np.array(X_test_list), dtype=T.float)\n",
    "y_test = T.tensor(np.array(y_test_list), dtype=T.long) - 1\n",
    "\n",
    "# Add channel dimension | image size: (channel, height, width)\n",
    "X_train = X_train.unsqueeze(1)\n",
    "X_test = X_test.unsqueeze(1)\n",
    "\n",
    "# convert to tensor dataset (train, val, test)\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_split = int(0.25 * len(train_dataset))\n",
    "train_dataset, val_dataset = random_split(train_dataset, [len(train_dataset) - val_split, val_split])\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# create data loaders (train, val, test) | image size: (batch, channel, height, width)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train obs: 750 - Val obs: 250 - Test obs: 1000\n",
      "\n",
      "Label: tensor(4)\n",
      "\n",
      "Image shape: torch.Size([1, 100, 100])\n",
      "\n",
      "Batch shape: torch.Size([64, 1, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "print('Train obs: {} - Val obs: {} - Test obs: {}'.format(len(train_dataset), len(val_dataset), len(test_dataset)))\n",
    "print('\\nLabel:', train_dataset[0][1])\n",
    "\n",
    "print('\\nImage shape:', train_dataset[0][0].shape)  # dimensions first dataset item\n",
    "\n",
    "batch_x, batch_y = next(iter(train_loader))  # dimensions first data loader batch\n",
    "print('\\nBatch shape:', batch_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitCNN(LightningModule):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes)\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        # CNN block - image size 100*100\n",
    "        self.CNN_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        # FC block - image batch size: torch.Size([32, 128, 12, 12])\n",
    "        self.FC_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=128 * 12 * 12, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.CNN_layers(x)\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = self.FC_layers(x)  # no activation and no softmax at the end\n",
    "        return x  \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = T.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=True)\n",
    "        self.log('train_acc', self.accuracy(y_hat, y), prog_bar=True, on_step=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "\n",
    "        self.log('val_loss', loss, prog_bar=True, on_step=True)\n",
    "        self.log('val_acc', self.accuracy(y_hat, y), prog_bar=True, on_step=True)\n",
    "        return loss\n",
    "\n",
    "    # def validation_epoch_end(self, outputs):\n",
    "    #     avg_loss = T.stack([x['val_loss'] for x in outputs]).mean()\n",
    "    #     tensorboard_logs = {'val_loss': avg_loss}\n",
    "    #     return {'val_loss': avg_loss, 'log': tensorboard_logs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "if T.cuda.is_available():\n",
    "    device = T.device('cuda')\n",
    "else:\n",
    "    device = T.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = LitCNN(input_size=100*100, num_classes=7)\n",
    "model.to(device)\n",
    "\n",
    "# Move data to GPU\n",
    "train_loader.to(device)\n",
    "val_loader.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\fer\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:474: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "logger = TensorBoardLogger('../tensorboard_logs', 'my_model')\n",
    "trainer = pl.Trainer(logger=logger, max_epochs=2, fast_dev_run=False, gpus=1 if device.type == 'cuda' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | accuracy   | MulticlassAccuracy | 0     \n",
      "1 | CNN_layers | Sequential         | 92.7 K\n",
      "2 | FC_layers  | Sequential         | 2.4 M \n",
      "--------------------------------------------------\n",
      "2.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 M     Total params\n",
      "9.812     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\fer\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1609: PossibleUserWarning: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 16/16 [00:05<00:00,  2.79it/s, loss=1.4, v_num=3, train_loss=1.160, train_acc=0.565, val_loss_step=1.620, val_acc_step=0.448, val_loss_epoch=1.450, val_acc_epoch=0.460] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 16/16 [00:05<00:00,  2.75it/s, loss=1.4, v_num=3, train_loss=1.160, train_acc=0.565, val_loss_step=1.620, val_acc_step=0.448, val_loss_epoch=1.450, val_acc_epoch=0.460]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9968), started 0:03:11 ago. (Use '!kill 9968' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6ca2fdfa5802e499\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6ca2fdfa5802e499\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ../tensorboard_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "y_hat = model(X_test)\n",
    "y_hat = y_hat.argmax(dim=1)\n",
    "y_hat = y_hat.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       145\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.00      0.00      0.00        27\n",
      "           3       0.64      1.00      0.78       640\n",
      "           4       0.57      0.03      0.05       140\n",
      "           5       0.00      0.00      0.00        44\n",
      "\n",
      "    accuracy                           0.64      1000\n",
      "   macro avg       0.20      0.17      0.14      1000\n",
      "weighted avg       0.49      0.64      0.51      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\fer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\envs\\fer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\envs\\fer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_test, y_hat))\n",
    "sns.heatmap(confusion_matrix(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f77961612acb5d081fd2373e515848ecc70065f5f997e07d4c2817dc8deb7852"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
